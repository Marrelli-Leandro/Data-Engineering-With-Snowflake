{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://drive.google.com/uc?export=view&id=1LqkEgbpZj8A99Y9T59eBp9fEIZbpg6P2\" alt=\"Snowflake Snowpark Classroom\" style=\"width: 800px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classroom 1.7 - Understanding Snowflake Snowpark Dataframes and their Methods\n",
    "\n",
    "In this notebook, you will learn how to play with data using Snowpark Dataframes and detailed hands-on with various methods\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this classroom, you should be able to:\n",
    "- Understanding on the Snowflake Snowpark Dataframes\n",
    "- Understanding on various types of operations on snowflake dataframes\n",
    "- Understanding on different and frequently used methods for snowflake dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get started with Snowpark for Python\n",
    "from assets.config import connection_builder\n",
    "session = connection_builder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Getting Started with Snowflake Snowpark Dataframes\n",
    "\n",
    "snowflake.snowpark.DataFrame represents a lazily-evaluated relational dataset that contains a collection of Row objects with columns defined by a schema (column name and type).\n",
    "\n",
    "- A DataFrame is considered lazy because it encapsulates the computation or query required to produce a relational dataset\n",
    "- The computation is not performed until you call a method that performs an action \n",
    "\n",
    "There are multiple ways to create a dataframe using snowpark\n",
    "\n",
    "1. Using session.Table() to create a dataframe\n",
    "2. Using session.read property of DataFrameReader to create a dataframe\n",
    "3. Creating new dataframe by applying transformation on existing dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import StructField,StructType,StringType,IntegerType\n",
    "session.file.put(local_file_name='assets/resources/csv_dataset.csv',stage_location='@TEST_STAGE',auto_compress=False,overwrite=True)\n",
    "\n",
    "# Creating Dataframe using session.table\n",
    "df_via_table = session.table('SNOWFLAKE.ACCOUNT_USAGE.WAREHOUSE_METERING_HISTORY')\n",
    "df_via_table.show()\n",
    "\n",
    "# Creating Dataframe using session.read property\n",
    "df_via_stage_file = session.read.schema(StructType([StructField('Email No.',StringType()),\n",
    "                                                    StructField('the',StringType()),\n",
    "                                                    StructField('to',StringType())])).csv('@TEST_STAGE/csv_dataset.csv')\n",
    "df_via_stage_file.show()\n",
    "\n",
    "# Creating Dataframe by applying transformation on existing dataframe\n",
    "dv_via_transformation = df_via_stage_file.filter(df_via_stage_file.to.try_cast(IntegerType()) > 10)\n",
    "dv_via_transformation.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Types of Operations on a Dataframe \n",
    "\n",
    "The operations on DataFrame can be divided into two types:\n",
    "\n",
    "- **Transformations** produce a new DataFrame from one or more existing DataFrames. Note that transformations are lazy and donâ€™t cause the DataFrame to be evaluated.\n",
    "\n",
    "- **Actions** cause the DataFrame to be evaluated. When you call a method that performs an action, Snowpark sends the SQL query for the DataFrame to the server for evaluation.\n",
    "\n",
    "Follow the Snowpark for Python Documentation to understand various use cases on Transformation and performing actions on the DataFrame - [Snowflake.Snowpark.DataFrame](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.DataFrame)\n",
    "\n",
    "---\n",
    "\n",
    "Complete List of All DataFrame Methods - [Here](https://docs.snowflake.com/en/developer-guide/snowpark/reference/python/latest/api/snowflake.snowpark.DataFrame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import StructType, StructField, IntegerType,StringType,FloatType\n",
    "schema = StructType([StructField('name',StringType()),\n",
    "                     StructField('age',IntegerType()),\n",
    "                     StructField('salary',FloatType())\n",
    "                     ])\n",
    "dataset = [['divyansh',22,150.00],\n",
    "           ['piyush',22,130.5],\n",
    "           ['piyush',28,160.85],\n",
    "           ['archana',29,190.25],\n",
    "           ['archana',29,190.25],\n",
    "           ['archana',29,None],\n",
    "           [None,None,190.25],\n",
    "           [None,None,float('nan')]]\n",
    "df = session.createDataFrame(data=dataset,schema=schema)\n",
    "\n",
    "\n",
    "# Hands-on for Aggregate Functions\n",
    "print('----------------- Aggregate Functions on DataFrame using dataFrame.agg() -----------------')\n",
    "df.group_by(df.age).agg((df.age,'max'),(df.salary,'median')).show()\n",
    "\n",
    "# Hands-on for Caching the DataFrame Result\n",
    "print('----------------- Caching DataFrame using dataframe.cache_result() and dataframe.drop_table()  -----------------')\n",
    "df_qh = session.table('SNOWFLAKE.ACCOUNT_USAGE.QUERY_HISTORY')\n",
    "df_qh_cache = df_qh.cache_result()\n",
    "df_qh_cache.delete(df_qh_cache.user_name=='DIVYANSH')\n",
    "print(df_qh_cache.count())\n",
    "print(df_qh.count())\n",
    "df_qh_cache2 = df_qh_cache.cache_result()\n",
    "df_qh_cache.drop_table() # Dropping the Cached Result\n",
    "df_qh_cache2.show() # Dataframe derived from Cached Results will work\n",
    "\n",
    "# DataFrame.count() To get the number of rows in the result \n",
    "print('----------------- Generating Number of Rows in Dataframe Result using dataframe.count()  -----------------')\n",
    "print(df_qh_cache2.count())\n",
    "\n",
    "# DataFrame.createOrReplaceTempView() To create a temporary view of the dataframe result \n",
    "print('----------------- Creating a temp View from Dataframe Result using dataframe.createOrReplaceTempView()  -----------------')\n",
    "df_qh_cache2.createOrReplaceTempView('df_qh_vw')\n",
    "session.sql('select * from df_qh_vw').show()\n",
    "\n",
    "# Joins Using Snowpark DataFrame\n",
    "print('----------------- Joins Example Using Snowpark Dataframe -----------------')\n",
    "df.crossJoin(df).show(100)\n",
    "\n",
    "df_test = df.fillna({'name':'test'})\n",
    "df.join(df_test,df.name == df_test.name,'inner').show()\n",
    "\n",
    "# Computing basic statistics for numeric columns, which includes count, mean, stddev, min, and max Using DataFrame.describe()\n",
    "print('----------------- Computing Basic Statistics using Dataframe.describe() -----------------')\n",
    "df.describe().show()\n",
    "\n",
    "# Generating Dataframe with distinct values from the current DataFrame using dataframe.distinct()\n",
    "print('----------------- Distinct Dataframe results using Dataframe.distinct() -----------------')\n",
    "df.distinct().show()\n",
    "\n",
    "# Dropping Columns from a dataframe using dataframe.drop()\n",
    "print('----------------- Dropping Age Column from DataFrame using Dataframe.drop() -----------------')\n",
    "df.drop('age').show()\n",
    "\n",
    "# Dropping Duplicates on given subset of columns from a dataframe using dataframe.dropDuplicates().\n",
    "# The result is non-deterministic when removing duplicated rows from the subset of columns but not all columns.\n",
    "print('----------------- Dropping Duplicates from DataFrame using Dataframe.dropDuplicates() -----------------')\n",
    "df.dropDuplicates('name','age').show()\n",
    "\n",
    "# Dropping Nulls/NaN using DataFrame.dropna that excludes all rows containing fewer than a specified number of non-null and non-NaN values in the specified columns.\n",
    "print('----------------- Dropping Nulls/NaNs from DataFrame using Dataframe.dropna() -----------------')\n",
    "df.dropna(how='any').show()\n",
    "df.dropna(thresh=1).show()\n",
    "df.dropna(subset='name').show()\n",
    "\n",
    "# Subtracting dataframes using dataframe.minus() or dataframe.subtract()\n",
    "print('----------------- Generating Difference in the dataframes using Dataframe.minus() or Dataframe.subtract() -----------------')\n",
    "df2 = df.dropna(how='any')\n",
    "df.minus(df2).show() \n",
    "\n",
    "# Printing the list of queries that will be executed to evaluate this DataFrame using dataframe.explain()\n",
    "print('----------------- Printing the list of queries that will be executed to evaluate dataframes using Dataframe.explain() -----------------')\n",
    "df_qh.explain()\n",
    "\n",
    "# Replacing all null and NaN values in the specified columns with the values provided using Dataframe.fillna()\n",
    "print('----------------- Replacing all null and NaN values in the specified columns with the values provided using Dataframe.fillna() -----------------')\n",
    "df.fillna({'name':'test','age':10,'salary':100.0}).show()\n",
    "\n",
    "# Filter rows based on the specified conditional expression using dataframe.filter() or dataframe.where()\n",
    "print('----------------- Filter rows based on the specified conditional expression -----------------')\n",
    "df.where((df.name.isin('divyansh','piyush') | (df.salary > 170.0))).show()\n",
    "\n",
    "# Generate Intersection of rows from 2 dataframe using dataframe.intersect()\n",
    "print('----------------- Intersect 2 Dataframes using dataframe.intersect() -----------------')\n",
    "df.intersect(df2).show()\n",
    "\n",
    "# Executing the query representing a DataFrame and return an iterator of Row objects using dataframe.toLocalIterator().\n",
    "print('----------------- Returning an iterator of Row objects using dataframe.toLocalIterator() -----------------')\n",
    "for rows in df.toLocalIterator():\n",
    "    print('name = ',rows[0])\n",
    "    print(' -age = ',rows[1])\n",
    "    print(' -salary = ',rows[2])\n",
    "\n",
    "# Snowpark Dataframe to Pandas DataFrame\n",
    "# Unlike to_pandas(), to_pandas_batches() method does not load all data into memory at once\n",
    "#print('----------------- Converting Snowpark Dataframe to Pandas using dataframe.to_pandas() / dataframe.to_pandas_batches() -----------------')\n",
    "df_pd = df.toPandas()\n",
    "display(df_pd)\n",
    "for pandas_df in df.to_pandas_batches():\n",
    "    print(pandas_df)\n",
    "\n",
    "   \n",
    "# Hands-on on Union / UnionAll / UnionByName / UnionAllByName\n",
    "print('----------------- Union Examples using Snowpark DataFrame -----------------')\n",
    "df.union(df2).show()\n",
    "df.unionAll(df2).show()\n",
    "df.unionByName(df2).show()\n",
    "df.unionAllByName(df2).show()\n",
    "\n",
    "# Introducing additional columns with the specified names using dataframe.withColumn() and dataframe.with_columns()\n",
    "print('----------------- Introducing additional columns with the specified names  -----------------')\n",
    "df.withColumn('sum_age_sal',df.salary + df.age).show()\n",
    "df.with_columns(['Salary By Age', '10pct Promotion'],[df.salary/df.age,df.salary * 1.1]).show()\n",
    "\n",
    "# Performing drop method on the dataframe\n",
    "print('----------------- Dropping data with any null value -----------------')\n",
    "df.dropna(how='any').show()\n",
    "print('----------------- Dropping data with all null value -----------------')\n",
    "df.dropna(how='all').show()\n",
    "print('----------------- Dropping duplicate data value -----------------')\n",
    "df.dropDuplicates().show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
